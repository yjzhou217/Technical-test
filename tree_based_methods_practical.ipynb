{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3c2db01-d1f9-4192-9aaf-2462aaeec49e",
      "metadata": {},
      "source": [
        "# Practical 4: Tree-based Methods\n",
        "\n",
        "This week will introduce the supervised learning framework and key\n",
        "metrics for evaluating supervised learning models using the London Fire\n",
        "Brigade dataset.\n",
        "\n",
        "## Learning Outcomes\n",
        "\n",
        "-   Understand the design and training of decision trees.\n",
        "-   Understand the principle of ensemble methods, including bagging and\n",
        "    boosting.\n",
        "-   Understand the design and strengths of random forests and gradient\n",
        "    boosting machines.\n",
        "-   Can apply tree-based methods from proper libraries (random forest\n",
        "    from sklearn and XGBoot from XGBoost).\n",
        "\n",
        "# Starting the Practical\n",
        "\n",
        "The process for every week will be the same: download the notebook to\n",
        "your `DSSS` folder (or wherever you keep your course materials), switch\n",
        "over to `JupyterLab` (which will be running in Podman/Docker) and get to\n",
        "work.\n",
        "\n",
        "If you want to save the completed notebook to your Github repo, you can\n",
        "`add`, `commit`, and `push` the notebook in Git after you download it.\n",
        "When you’re done for the day, save your changes to the file (this is\n",
        "very important!), then `add`, `commit`, and `push` your work to save the\n",
        "completed notebook.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> Suggestions for a Better Learning Experience:\n",
        ">\n",
        "> -   **Set your operating system and software language to English**:\n",
        ">     this will make it easier to follow tutorials, search for solutions\n",
        ">     online, and understand error messages.\n",
        ">\n",
        "> -   **Save all files to a cloud storage service**: use platforms like\n",
        ">     Google Drive, OneDrive, Dropbox, or Git to ensure your work is\n",
        ">     backed up and can be restored easily when the laptop gets stolen\n",
        ">     or broken.\n",
        ">\n",
        "> -   **Avoid whitespace in file names and column names in datasets**\n",
        "\n",
        "# Revisiting London Fire Brigade Dataset\n",
        "\n",
        "This week, we will continue using the London Fire Brigade (LFB) dataset\n",
        "for supervised learning tasks. For the context of LFB data and the two\n",
        "learning tasks, please refer to Week 2 practical notebook. Remember that\n",
        "we formulated two supervised learning tasks using the LFB dataset and\n",
        "random forest:\n",
        "\n",
        "1.  *Regression*: predicting daily LFB callouts in Greater London, using\n",
        "    weather and temporal features.\n",
        "2.  *Classification*: predicting whether a fire incident is a false\n",
        "    alarm given the location available at the time of the callout, which\n",
        "    includes time of day, day of week, building type (dwelling or\n",
        "    commercial).\n",
        "\n",
        "In this practical, we will apply the algorithms of decision tree, random\n",
        "forest, and XGBoost to these two tasks and look into the model design\n",
        "and performance. For each task, we will train three algorithms with\n",
        "hyperparameter tuning using cross-validation, and then compare their\n",
        "performance.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> This practical is closely related to the Week-2 (introduction to the\n",
        "> dataset & metrics) and Week-3 content (supervised learning workflow\n",
        "> and cross validation). If you are not familiar with the dataset or\n",
        "> train-test split or cross validation, please review Week-3 lecture\n",
        "> notes and practical before proceeding.\n",
        "\n",
        "# Predicting daily LFB callouts\n",
        "\n",
        "We will start with a regression tree to predict daily LFB callouts using\n",
        "weather and temporal features, using train-test split and\n",
        "cross-validation.\n",
        "\n",
        "## Regression tree\n",
        "\n",
        "Firstly, we import the dataset and prepare the train-test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9e9c526",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import data from https://raw.githubusercontent.com/huanfachen/DSSS_2025/refs/heads/main/data/LFB_2023_daily_data.csv\n",
        "import pandas as pd\n",
        "# suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df_lfb_daily = pd.read_csv(\"https://raw.githubusercontent.com/huanfachen/DSSS_2025/refs/heads/main/data/LFB_2023_daily_data.csv\")\n",
        "\n",
        "# using Random Forest to predict IncidentCount using weather, weekday, weekend, and bank holiday info\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# prepare data for modeling\n",
        "feature_cols = ['TX', 'TN', 'TG', 'SS', 'SD','RR','QQ', 'PP','HU','CC', 'IsWeekend', 'IsBankHoliday', 'weekday']\n",
        "X = df_lfb_daily[feature_cols]\n",
        "y = df_lfb_daily['IncidentCount']\n",
        "\n",
        "# one-hot encode the 'weekday' column\n",
        "X = pd.get_dummies(X, columns=['weekday'], drop_first=True)\n",
        "\n",
        "# split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c0ed36c-4946-4ac5-97d1-8f163b39675e",
      "metadata": {},
      "source": [
        "Then, we will train a regression tree model using\n",
        "`DecisionTreeRegressor` from `sklearn.tree`, tune the hyperparameters\n",
        "using cross-validation, and evaluate its performance on both the\n",
        "training and testing data.\n",
        "\n",
        "The hyperparameters to tune include:\n",
        "\n",
        "-   `max_depth`: maximum depth of the tree (default at None, meaning\n",
        "    this hyperparameter is not used and nodes are expanded until all\n",
        "    leaves are pure or until all leaves contain less tha\n",
        "    min_samples_split samples)\n",
        "-   `min_samples_split`: minimum number of samples required to split an\n",
        "    internal node (default at 2)\n",
        "-   `min_samples_leaf`: minimum number of samples required to be at a\n",
        "    leaf node (default at 1)\n",
        "\n",
        "To get a sense of the range of these hyperparameters, we can try a\n",
        "regression tree and print the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8edf916",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max depth: 19\n",
            "Average samples at internal nodes: 11.767605633802816\n",
            "Average samples at leaf nodes: 1.0210526315789474\n",
            "Train R-squared: 1.000\n",
            "Test R-squared: -0.425\n"
          ]
        }
      ],
      "source": [
        "# train a regression tree using training data and print max_depth, average number of samples at internal nodes, average number of samples at leaf nodes\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "dt = DecisionTreeRegressor(random_state=12)\n",
        "dt.fit(X_train, y_train)\n",
        "print(\"Max depth:\", dt.get_depth())\n",
        "internal_node_samples = [dt.tree_.n_node_samples[i] for i in range(dt.tree_.node_count) if dt.tree_.children_left[i] != dt.tree_.children_right[i]]\n",
        "leaf_node_samples = [dt.tree_.n_node_samples[i] for i in range(dt.tree_.node_count) if dt.tree_.children_left[i] == dt.tree_.children_right[i]]\n",
        "print(\"Average samples at internal nodes:\", sum(internal_node_samples)/len(internal_node_samples))\n",
        "print(\"Average samples at leaf nodes:\", sum(leaf_node_samples)/len(leaf_node_samples))\n",
        "\n",
        "# print train and test R-squared\n",
        "train_r2 = r2_score(y_train, dt.predict(X_train))\n",
        "test_r2 = r2_score(y_test, dt.predict(X_test))\n",
        "print(f\"Train R-squared: {train_r2:.3f}\")\n",
        "print(f\"Test R-squared: {test_r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "694d6b4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 15}\n",
            "Best CV R-squared: 0.141\n",
            "Train R-squared: 0.480\n",
            "Test R-squared: 0.062\n"
          ]
        }
      ],
      "source": [
        "# code for cross-validation and hyperparameter tuning for DecisionTreeRegressor based on three hyperparameters above. Print the training, cross-validation, and testing R-squared.\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "param_grid = {\n",
        "  'max_depth': [None, 5, 10, 20],\n",
        "  'min_samples_split': [5, 10, 15],\n",
        "  'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "  estimator=DecisionTreeRegressor(random_state=12),\n",
        "  param_grid=param_grid,\n",
        "  cv=5,\n",
        "  scoring='r2',\n",
        "  n_jobs=-1,\n",
        "  return_train_score=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "# print best hyperparameters and best CV R-squared\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(f\"Best CV R-squared: {grid.best_score_:.3f}\")\n",
        "# retrain with optimal hyperparameters\n",
        "best_params = grid.best_params_\n",
        "best_model = DecisionTreeRegressor(random_state=20, **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "# r2 on training and testing data\n",
        "train_r2 = r2_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train R-squared: {train_r2:.3f}\")\n",
        "test_r2 = r2_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test R-squared: {test_r2:.3f}\")\n",
        "# store the accuracy of CV, train, and test R-squared in a dictionary\n",
        "dt_results = {\n",
        "  'CV_R2': grid.best_score_,\n",
        "  'Train_R2': train_r2,\n",
        "  'Test_R2': test_r2\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f205975-e18e-49c5-b30b-c4c11a517d76",
      "metadata": {},
      "source": [
        "Question #1: **can you estimate the number of regression tree models\n",
        "that have been trained during cross-validation with grid search?** Hint:\n",
        "you can calculate it based on number of hyperparameter combinations and\n",
        "number of folds in cross-validation, or using the `cv_results_`\n",
        "attribute of the `GridSearchCV` object.\n",
        "\n",
        "Question #2: **what is the criterion used in the regression tree to\n",
        "split nodes by default?** Hint: check the documentation of\n",
        "`DecisionTreeRegressor` in sklearn.\n",
        "\n",
        "## Random forest\n",
        "\n",
        "We will train a random forest model using a similar workflow as above.\n",
        "The hyperparameters to tune include: - `max_depth`: maximum depth of the\n",
        "tree (default at None, meaning this hyperparameter is not used and nodes\n",
        "are expanded until all leaves are pure or until all leaves contain less\n",
        "tha min_samples_split samples) - `min_samples_leaf`: minimum number of\n",
        "samples required to be at a leaf node (default at 1) - `max_features`:\n",
        "number of features to consider when looking for the best split. This\n",
        "feature controls the randomness of each tree; more randomness can be\n",
        "achieved by setting smaller values (default to 1.0, meaning all features\n",
        "are considered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0b84d693",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 10, 'max_features': 0.5, 'min_samples_leaf': 1}\n",
            "Best CV R-squared: 0.368\n",
            "Train R-squared: 0.876\n",
            "Test R-squared: 0.169\n"
          ]
        }
      ],
      "source": [
        "# use cross validation to tune RandomForestRegressor. No need to impoort data or split data again, as it is the same as above.\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "param_grid = {\n",
        "  'max_depth': [None, 5, 10, 20],\n",
        "  'min_samples_leaf': [1, 2, 4],\n",
        "  'max_features': ['sqrt', 'log2', 0.5, 1.0]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "  estimator=RandomForestRegressor(random_state=23),\n",
        "  param_grid=param_grid,\n",
        "  cv=5,\n",
        "  scoring='r2',\n",
        "  n_jobs=-1,\n",
        "  return_train_score=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "# print best hyperparameters and best CV R-squared\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(f\"Best CV R-squared: {grid.best_score_:.3f}\")\n",
        "# retrain with optimal hyperparameters\n",
        "best_params = grid.best_params_\n",
        "best_model = RandomForestRegressor(random_state=20, **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "# r2 on training and testing data\n",
        "train_r2 = r2_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train R-squared: {train_r2:.3f}\")\n",
        "test_r2 = r2_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test R-squared: {test_r2:.3f}\")\n",
        "\n",
        "# store the accuracy of CV, train, and test R-squared in a dictionary\n",
        "rf_results = {\n",
        "  'CV_R2': grid.best_score_,\n",
        "  'Train_R2': train_r2,\n",
        "  'Test_R2': test_r2\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f3d4ba4-d8f4-41b3-b9e4-2c8695086115",
      "metadata": {},
      "source": [
        "## XGBoost\n",
        "\n",
        "We will train an XGBoost model using a similar workflow as above.\n",
        "XGBoost stands for Extreme Gradient Boosting, which is an efficient,\n",
        "scalable, and industry-standard implementation of gradient boosting\n",
        "algorithm. We will use the `XGBoostRegressor` from `xgboost` library to\n",
        "train the model. Although this library is different from `sklearn`, it\n",
        "provides a sklearn-style interface, which makes it easy to use.\n",
        "\n",
        "The hyperparameters to tune include: - `max_depth`: maximum depth of the\n",
        "tree; increasing this value will make the model more complex and more\n",
        "likely to overfit. (default at 6) - `min_split_loss` (called `gamma` in\n",
        "XGBoost functions): minimum loss reduction required to make a further\n",
        "partition on a leaf node of the tree. The larger this value, the more\n",
        "*conservative* the algorithm will be. (default at 0) - `subsample`: the\n",
        "fraction of observations to be randomly sampled for each tree. Setting\n",
        "it to 0.5 means that XGBoost would randomly sample half of the training\n",
        "data prior to growing trees. and this will prevent overfitting.\n",
        "Subsampling will occur once in every boosting iteration. (default at\n",
        "1.0, meaning all observations are used to build each tree)\n",
        "\n",
        "Some notes on hyperparameter tuning of XGBoost can be found in [this\n",
        "post](https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8d0ca434",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 5, 'min_split_loss': 1, 'subsample': 0.7}\n",
            "Best CV R-squared: 0.337\n",
            "Train R-squared: 1.000\n",
            "Test R-squared: 0.063\n"
          ]
        }
      ],
      "source": [
        "# use cross validation to tune XGBoostRegressor, see hyperparameters above. No need to impoort data or split data again, as it is the same as above.\n",
        "from xgboost import XGBRegressor\n",
        "param_grid = {\n",
        "  'max_depth': [3, 5, 7],\n",
        "  'min_split_loss': [0, 1, 5],\n",
        "  'subsample': [0.5, 0.7, 1.0]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "  estimator=XGBRegressor(random_state=42, objective='reg:squarederror', eval_metric='rmse'),\n",
        "  param_grid=param_grid,\n",
        "  cv=5,\n",
        "  scoring='r2',\n",
        "  n_jobs=-1,\n",
        "  return_train_score=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "# print best hyperparameters and best CV R-squared\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(f\"Best CV R-squared: {grid.best_score_:.3f}\")\n",
        "# retrain with optimal hyperparameters\n",
        "best_params = grid.best_params_\n",
        "best_model = XGBRegressor(random_state=42, objective='reg:squarederror', eval_metric='rmse', **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "# r2 on training and testing data\n",
        "train_r2 = r2_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train R-squared: {train_r2:.3f}\")\n",
        "test_r2 = r2_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test R-squared: {test_r2:.3f}\")\n",
        "# store the accuracy of CV, train, and test R-squared in a dictionary\n",
        "xgb_results = {\n",
        "  'CV_R2': grid.best_score_,\n",
        "  'Train_R2': train_r2,\n",
        "  'Test_R2': test_r2\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c04ed2-baa0-42f8-bfc7-ef0e7ddcefbe",
      "metadata": {},
      "source": [
        "# Model performance comparison\n",
        "\n",
        "Now that we have trained and tuned three models (regression tree, random\n",
        "forest, and XGBoost), we can compare their performance on the training,\n",
        "cross-validated, and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a9258866",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               CV_R2  Train_R2  Test_R2\n",
            "Decision Tree  0.141     0.480    0.062\n",
            "Random Forest  0.368     0.876    0.169\n",
            "XGBoost        0.337     1.000    0.063\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "results_df = pd.DataFrame({\n",
        "  'Decision Tree': dt_results,\n",
        "  'Random Forest': rf_results,\n",
        "  'XGBoost': xgb_results\n",
        "}).T\n",
        "print(results_df.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d8a579e-a766-4b86-a917-5ede68d2da40",
      "metadata": {},
      "source": [
        "The results show that the decision tree model is **underfitting** the\n",
        "training data, as its accuracy on the training and testing data is both\n",
        "low. The XGBoost model overfits the training data (R2=1.0) but doesn’t\n",
        "generalise well to unseen data (R2=0.063). Finally, the random forest\n",
        "model achieves the best performance on the testing data (R2=0.169) and\n",
        "is less prone to overfitting compared to XGBoost.\n",
        "\n",
        "# Classification task: predicting false alarms in fire incidents\n",
        "\n",
        "We will now apply the same workflow to the classification task of\n",
        "predicting false alarms in fire incidents using decision tree, random\n",
        "forest, and XGBoost classifiers.\n",
        "\n",
        "First, we will import the dataset and prepare the train-test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f23a4076",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "proportion of Fire and False Alarm:\n",
            "IncidentGroup\n",
            "False Alarm    0.796176\n",
            "Fire           0.203824\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# import data from https://raw.githubusercontent.com/huanfachen/DSSS_2025/refs/heads/main/data/LFB_2023_data.csv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_lfb = pd.read_csv(\"https://raw.githubusercontent.com/huanfachen/DSSS_2025/refs/heads/main/data/LFB_2023_data.csv\")\n",
        "# add DayOfWeek column\n",
        "df_lfb['DayOfWeek'] = pd.to_datetime(df_lfb['DateOfCall']).dt.day_name()\n",
        "# remove 'Special Service' type\n",
        "df_lfb = df_lfb[df_lfb['IncidentGroup'].isin(['False Alarm', 'Fire'])]\n",
        "\n",
        "# proportion of both class\n",
        "print(\"proportion of Fire and False Alarm:\")\n",
        "print(df_lfb['IncidentGroup'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7830850c-3eab-4aea-a77f-d7c614bcf8bd",
      "metadata": {},
      "source": [
        "Then, we will prepare the data for train-test split and model training.\n",
        "As the target variable is highly imbalanced (nearly 80% false alarms and\n",
        "20% actual fires), we will use stratified sampling in train-test split\n",
        "to ensure that both training and testing sets have similar class\n",
        "distributions.\n",
        "\n",
        "As discussed in W2, recall is a more suitable metric than accuracy or\n",
        "precision for evaluating this classification task, as we would like to\n",
        "minimise false negatives (i.e. predicting a fire incident as a false\n",
        "alarm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d64bb12e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare data for modelling\n",
        "feature_cols = ['HourOfCall', \n",
        "'DayOfWeek',\n",
        "'PropertyCategory']\n",
        "X = df_lfb[feature_cols]\n",
        "\n",
        "# one-hot encode categorical features\n",
        "X = pd.get_dummies(X, columns=[\n",
        "  'DayOfWeek', \n",
        "  'PropertyCategory'], drop_first=True)\n",
        "\n",
        "y = df_lfb['IncidentGroup'].map({'False Alarm': 0, 'Fire': 1})  # map to binary labels\n",
        "\n",
        "# split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5467f691-e39c-4ecf-9e8d-0028014bf8f3",
      "metadata": {},
      "source": [
        "Can you complete the following code (replacing ?? with code) to train a\n",
        "decision tree, random forest, and XGBoost classifier?\n",
        "\n",
        "## Classification tree\n",
        "\n",
        "#### Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "93d773e7-552b-49ee-905d-caec45bf4291",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "Best CV recall: 0.586\n",
            "Train recall: 0.586\n",
            "Test recall: 0.590\n",
            "Train accuracy: 0.881\n",
            "Test accuracy: 0.883\n"
          ]
        }
      ],
      "source": [
        "# train a classification tree using training data and cross validation with hyperparameter tuning. Print the training, cross-validation, and testing accuracy.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import recall_score, accuracy_score\n",
        "\n",
        "param_grid = {\n",
        "  'max_depth': [None, 5, 10, 20],\n",
        "  'min_samples_split': [5, 10, 15],\n",
        "  'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "  estimator=DecisionTreeClassifier(random_state=12),\n",
        "  param_grid=param_grid,\n",
        "  cv=5,\n",
        "  scoring='recall',\n",
        "  n_jobs=-1,\n",
        "  return_train_score=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "# print best hyperparameters and best CV accuracy\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(f\"Best CV recall: {grid.best_score_:.3f}\")\n",
        "# retrain with optimal hyperparameters\n",
        "best_params = grid.best_params_\n",
        "best_model = DecisionTreeClassifier(random_state=20, **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# recall on training and testing data\n",
        "train_recall = recall_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train recall: {train_recall:.3f}\")\n",
        "test_recall = recall_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test recall: {test_recall:.3f}\")\n",
        "\n",
        "# accuracy on training and testing data\n",
        "train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
        "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
        "\n",
        "# store the recall of CV, train, and test in a dictionary\n",
        "dt_clf_results = {\n",
        "  'CV_Recall': grid.best_score_,\n",
        "  'Train_Recall': train_recall,\n",
        "  'Test_Recall': test_recall,\n",
        "  'Train_Accuracy': train_accuracy,\n",
        "  'Test_Accuracy': test_accuracy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8adbeb3-f2fe-4210-8b27-70b21b5ab78b",
      "metadata": {},
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7c8b4b09",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 5, 'max_features': 0.5, 'min_samples_leaf': 1}\n",
            "Best CV accuracy: 0.586\n",
            "Train recall: 0.586\n",
            "Test recall: 0.590\n",
            "Train accuracy: 0.881\n",
            "Test accuracy: 0.883\n"
          ]
        }
      ],
      "source": [
        "# use cross validation to tune RandomForestClassifier. No need to impoort data or split data again, as it is the same as above.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "param_grid = {\n",
        "  'max_depth': [None, 5, 10, 20],\n",
        "  'min_samples_leaf': [1, 2, 4],\n",
        "  'max_features': ['sqrt', 'log2', 0.5, 1.0]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "  estimator=RandomForestClassifier(random_state=23),\n",
        "  param_grid=param_grid,\n",
        "  cv=5,\n",
        "  scoring='recall',\n",
        "  n_jobs=-1,\n",
        "  return_train_score=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "# print best hyperparameters and best CV accuracy\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(f\"Best CV accuracy: {grid.best_score_:.3f}\")\n",
        "# retrain with optimal hyperparameters\n",
        "best_params = grid.best_params_\n",
        "best_model = RandomForestClassifier(random_state=20, **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "# recall on training and testing data\n",
        "train_recall = recall_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train recall: {train_recall:.3f}\")\n",
        "test_recall = recall_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test recall: {test_recall:.3f}\")\n",
        "# accuracy on training and testing data\n",
        "train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
        "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
        "\n",
        "# store the recall of CV, train, and test in a dictionary\n",
        "rf_clf_results = {\n",
        "  'CV_Recall': grid.best_score_,\n",
        "  'Train_Recall': train_recall,\n",
        "  'Test_Recall': test_recall,\n",
        "  'Train_Accuracy': train_accuracy,\n",
        "  'Test_Accuracy': test_accuracy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed34d171-70fb-4dd2-b30f-810af515aa0a",
      "metadata": {},
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2aaae42e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 3, 'min_split_loss': 0, 'subsample': 1.0}\n",
            "Best CV accuracy: 0.587\n",
            "Train recall: 0.587\n",
            "Test recall: 0.591\n",
            "Train accuracy: 0.881\n",
            "Test accuracy: 0.883\n"
          ]
        }
      ],
      "source": [
        "# use cross validation to tune XGBClassifier, see hyperparameters above. No need to impoort data or split data again, as it is the same as above.\n",
        "from xgboost import XGBClassifier\n",
        "param_grid = {\n",
        "  'max_depth': [3, 5, 7],\n",
        "  'min_split_loss': [0, 1, 5],\n",
        "  'subsample': [0.5, 0.7, 1.0]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "  estimator=XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
        "  param_grid=param_grid,\n",
        "  cv=5,\n",
        "  scoring='recall',\n",
        "  n_jobs=-1,\n",
        "  return_train_score=True\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "# print best hyperparameters and best CV accuracy\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(f\"Best CV accuracy: {grid.best_score_:.3f}\")\n",
        "# retrain with optimal hyperparameters\n",
        "best_params = grid.best_params_\n",
        "best_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "# recall on training and testing data\n",
        "train_recall = recall_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train recall: {train_recall:.3f}\")\n",
        "test_recall = recall_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test recall: {test_recall:.3f}\")\n",
        "# accuracy on training and testing data\n",
        "train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
        "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
        "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
        "\n",
        "# store the recall of CV, train, and test in a dictionary\n",
        "xgb_clf_results = {\n",
        "  'CV_Recall': grid.best_score_,\n",
        "  'Train_Recall': train_recall,\n",
        "  'Test_Recall': test_recall,\n",
        "  'Train_Accuracy': train_accuracy,\n",
        "  'Test_Accuracy': test_accuracy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b78b166-180c-4988-90b3-99e0f5ad4fec",
      "metadata": {},
      "source": [
        "## Model performance comparison\n",
        "\n",
        "We can collate the results from the three classification models and\n",
        "compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a3189857",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               CV_Recall  Train_Recall  Test_Recall  Train_Accuracy  \\\n",
            "Decision Tree      0.586         0.586        0.590           0.881   \n",
            "Random Forest      0.586         0.586        0.590           0.881   \n",
            "XGBoost            0.587         0.587        0.591           0.881   \n",
            "\n",
            "               Test_Accuracy  \n",
            "Decision Tree          0.883  \n",
            "Random Forest          0.883  \n",
            "XGBoost                0.883  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "results_clf_df = pd.DataFrame({\n",
        "  'Decision Tree': dt_clf_results,\n",
        "  'Random Forest': rf_clf_results,\n",
        "  'XGBoost': xgb_clf_results\n",
        "}).T\n",
        "print(results_clf_df.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da33fd10-dfd0-49cb-ac13-1c60307a2bff",
      "metadata": {},
      "source": [
        "The results show that the performance is very similar across the three\n",
        "models, although XGBoost achieves slightly higher recall on the training\n",
        "and testing data. A recall of around 0.6 is not very high, which\n",
        "indicates that approximately 40% of actual fire incidents are\n",
        "misclassified as false alarms. The results also suggest that\n",
        "hyperparameter tuning doesn’t improve the model performance here. It is\n",
        "possible that the features used in this task are not very predictive of\n",
        "false alarms, and extra features (e.g. more accurate locations) may be\n",
        "needed to improve the model performance.\n",
        "\n",
        "# Summary\n",
        "\n",
        "We have demonstrated how to use tree-based methods for regression and\n",
        "classification tasks using London Fire Brigade dataset. In the\n",
        "regression task, decision tree underfits the data, while XGBoost\n",
        "overfits the training data. Random forest achieves the best performance\n",
        "and a good balance between bias and variance. In the classification\n",
        "task, all three models achieve similar performance and the recall is not\n",
        "very high, which indicates that more predictive features may be needed\n",
        "to improve the model performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
